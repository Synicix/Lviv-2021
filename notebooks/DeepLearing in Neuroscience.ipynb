{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
    "<a target=\"_blank\"  href=\"https://colab.research.google.com/github/eywalker/LVIV-2021/blob/main/notebooks/DeepLearing%20in%20Neuroscience.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
    "</td><td>\n",
    "<a target=\"_blank\"  href=\"https://github.com/eywalker/LVIV-2021/blob/main/notebooks/DeepLearing%20in%20Neuroscience.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Welcome to Deep Learning in Neuroscience by Edgar Y. Walker"
   ],
   "metadata": {
    "id": "xp0SO4gr2D7w"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a Jupyter notebook to accompany the course on \"Deep Learning in Neuroscience\" taught as part of the Lviv Data Science Summer School 2021. This notebook as well as any other relevant information can be found in the [GitHub repository](https://github.com/eywalker/lviv-2021)!\n",
    "\n",
    "In this course, we will learn how deep learning is getting utilized in studying neuroscience, specifically in building models of neurons to complex sensory inputs such as natural images. We will start by going through some neuroscience primer. We will then get our hands dirty by taking real neuronal responses recorded from mouse primary visual cortex (V1) as the mouse observes a bunch of natural images and developing a model to predict these responses. By the end of this course, you will gain some basic familiarity in utilizing deep learning models to predict responses of 1000s of neurons to natural images!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <font color='red'>NOTE: Please run this section at the very beginning of the first session!</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we get to dive in and learn how deep learning is used in neuroscience and get your first neural predictive model trained, we need to install some prerequisite packages and download some neuronal data!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting the code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to primarily use [PyTorch](https://pytorch.org) to build, train and evaluate our deep learning models and I am going to assume some familiarity with PyTorch already.\n",
    "\n",
    "Also to be able to handle the dataset containing neuronal activities, we are going to make our life easier by using a few existing libraries. I have prepared a library called [lviv2021](https://github.com/eywalker/lviv2021). This library has a dependency on [neuralpredictors](https://github.com/sinzlab/neuralpredictors), which is a collection of PyTorch layers, tools and other utilities that would prove helpful to train networks to predict neuronal responses.\n",
    "\n",
    "Let's go ahead and install this inside the Colab environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Install PyTorch dependency\n",
    "!pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    \n",
    "# Install \n",
    "!pip3 install git+https://github.com/eywalker/lviv-2021.git"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "m7dJ_i-tSPEq",
    "outputId": "bdc3f3f8-e451-4bd3-83d5-3f126b88f431"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to use the dataset made available for our recent paper [Lurz et al. ICLR 2021](https://github.com/sinzlab/Lurz_2020_code), predicting responses of mouse visual cortex to natural images. \n",
    "\n",
    "The dataset can take anywhere from 5-10 min to download, so please be sure to **run the following at the very beginning of the session!** We are going to first spend some time learning the basics of computational neuroscience in the study of system identification. It would be best that you let the download take place while we go over the neursocience primer so that it will be ready when we come back here to get our hands dirty!\n",
    "\n",
    "To download the data, simply execute the following cell, and let it run till completion."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!git clone https://gin.g-node.org/cajal/Lurz2020.git /content/data"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsNehEZlTSL4",
    "outputId": "8e2984ad-9f32-4dfd-b8b7-4536f2e53823"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Developing models of neural population responses to natural images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that you have been primed with just enough background neuroscience, let's get our hand dirty and try to build our first neural predictive models.\n",
    "\n",
    "As part of the setup, we have downloaded a 2-photon imaging dataset from mouse primary visual cortex as we present 1000s of natural images (if not done yet, please do so immediately by stepping through the beginning sections of this notebook)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Navigating the neuroscience data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As with any data science project, you must start by understanding your data! Let's take some time to navigate the data you downloaded."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "ls ./data/static20457-5-9-preproc0/"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "change.log  config.json  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mmeta\u001b[0m/\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ls ./data/static20457-5-9-preproc0/data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ls ./data/static20457-5-9-preproc0/data/responses | head -30"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ls ./data/static20457-5-9-preproc0/data/images | head -30"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that both responses and contained in collections of `numpy` files named like `1.npy` or `31.npy`. The number here corresponds to a specific **trial** or simply different image presentation during an experiment.\n",
    "\n",
    "Let's take a look at some of these files."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading data files one at a time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's pick some trial and load the image as well as the response"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trial_idx = 1100\n",
    "trial_image = np.load(f'./data/static20457-5-9-preproc0/data/images/{trial_idx}.npy')\n",
    "trial_responses = np.load(f'./data/static20457-5-9-preproc0/data/responses/{trial_idx}.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The image is shaped as $\\text{channel} \\times \\text{height} \\times \\text{width}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trial_image.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.imshow(trial_image.squeeze(), cmap='gray', vmin=0, vmax=255)\n",
    "plt.axis('off')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In contrast, the shape of `trial_response` is simply the number of neurons"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trial_responses.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trial_responses.min() # responses are practically always >= 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trial_responses.max()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "ax.hist(trial_responses, 100);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see most neuron's responses stay very close to 0 - signifying no activity."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the entire dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we can inspect the image and the corresponding neural population responses one image at a time, this is quite cumbersome and also impractical for use in network training. Fortunately, the `lviv` package provides us with a convenience function that will help to load the entire dataset as PyTorch dataloaders."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from lviv.dataset import load_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we prepare the dataloaders, we get to specify the batch size."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dataloaders = load_dataset(path = '/content/data/static20457-5-9-preproc0', batch_size=60)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function returns a dictionary consisting of three dataloaders for training, validation, and test set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataloaders"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's specifically look at the trainset dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_loader = dataloaders['train']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Total number of images can be checked as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "len(train_loader.sampler)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4472"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can inspect what it returns per batch:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "images, responses = next(iter(train_loader))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "images.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([60, 1, 36, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "responses.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([60, 5335])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, you can see it returns a batch size of 60 images and responses for all neurons."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similar inspection can be done on the **validation** and **testing** dataloaders."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# number of images in validation set\n",
    "len(dataloaders['validation'].sampler)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# number of images in test set\n",
    "len(dataloaders['test'].sampler)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You might think that we have a lot of images in test set, but this is because test set consists of repeated images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some additional trial information can be observed by accessing the underlying PyTorch dataset object and looking at the `trial_info`. Note that this is not part of the standard PyTorch dataset/dataloader interface, but rather a feature specifically provided by the library!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Access to the dataset object that underlies all dataloaders\n",
    "testset = dataloaders['test'].dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "test_trials = np.where(testset.trial_info['tiers'] == 'test')[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "image_ids = testset.trial_info['frame_image_id']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "np.unique(image_ids[test_trials])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 104,  128,  183,  355,  479,  483,  656,  803,  830,  936, 1201,\n",
       "       1494, 1596, 1652, 1656, 1682, 1731, 1756, 1796, 2005, 2008, 2014,\n",
       "       2159, 2214, 2389, 2586, 2710, 2746, 2747, 2803, 2816, 2825, 2954,\n",
       "       3018, 3107, 3144, 3163, 3372, 3427, 3438, 3487, 3507, 3562, 3702,\n",
       "       3847, 3924, 4231, 4295, 4373, 4397, 4400, 4430, 4594, 4619, 4667,\n",
       "       4674, 4717, 4739, 4782, 4812, 4814, 4821, 4923, 4953, 5034, 5128,\n",
       "       5166, 5225, 5264, 5288, 5322, 5334, 5399, 5402, 5504, 5640, 5671,\n",
       "       5679, 5754, 5782, 6013, 6034, 6066, 6082, 6205, 6238, 6248, 6490,\n",
       "       6562, 6773, 6790, 6831, 6886, 7017, 7028, 7107, 7119, 7120, 7154,\n",
       "       7495])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "len(np.unique(image_ids[test_trials]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So you can see that the test set consists of 100 unique images, each repeated up to 10 times."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "testset.trial_info.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['trial_idx',\n",
       " 'session',\n",
       " 'frame_trial_ts',\n",
       " 'frame_last_flip',\n",
       " 'frame_image_id',\n",
       " 'frame_image_class',\n",
       " 'frame_pre_blank_period',\n",
       " 'condition_hash',\n",
       " 'tiers',\n",
       " 'animal_id',\n",
       " 'scan_idx',\n",
       " 'frame_presentation_time']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "testset.trial_info.frame_image_id  # gives information about presented image ID"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1301, 5927, 3982, ...,  464,  819, 3025])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "testset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FileTreeDataset /content/data/static20457-5-9-preproc0 (n=5993 items)\n",
       "\timages, responses"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dataloaders"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fbcf66025b0>,\n",
       " 'validation': <torch.utils.data.dataloader.DataLoader at 0x7fbcf66024f0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fbcf66021f0>}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "len(dataloaders['validation'].dataset.trial_info.frame_image_id)  # gives information about presented image ID"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5993"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling the neuronal responses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have successfully loaded the dataset and inspected its contents, it's time for us to start **modeling** the responses.\n",
    "\n",
    "We will start by building a very basic **Linear-Nonlinear model** - which is nothing more than a shallow neural network with single linear layer followed by an activation function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear-Nonlinear (LN) model"
   ],
   "metadata": {
    "id": "TcVMbaG9xXNY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Background"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arguably one of the simplest model of a neuron's response to a stimulus is the **linear-nonlinear (LN) model**. \n",
    "\n",
    "Given an image $I \\in \\mathbb{R}^{h\\,\\times\\,w}$ where $h$ and $w$ are the height and the width of the image, respectively, let us collapse the image into a vector $x \\in \\mathbb{R}^{hw}$.\n",
    "\n",
    "A single neuron's response $r$ under linear-nonlinear model can then be expressed as:\n",
    "$$\n",
    "r = a(w^\\top x + b),\n",
    "$$\n",
    "where $w \\in \\mathbb{R}^{hw}$ and $b \\in \\mathbb{R}$ are **weight** and **bias**, and $a:\\mathbb{R}\\mapsto\\mathbb{R}$ is a scalar **activating function**.\n",
    "\n",
    "We can in fact extend to capture the responses of all $N$ neurons simultaneously as:\n",
    "\n",
    "$$\n",
    "\\mathbf{r} = a(\\mathbf{W} x + \\mathbf{b}),\n",
    "$$\n",
    "where $\\mathbf{r} \\in \\mathbb{R}^{N}$, $\\mathbf{W} \\in \\mathbb{R}^{N\\,\\times\\,hw}$ and $\\mathbf{b} \\in \\mathbb{R}^{N}$.\n",
    "\n",
    "Hence, each neuron weights each pixel of the image according to the weight $w$ (a column of $\\mathbf{W}$) and thus characterizes how much the each neuron \"cares\" about a specific pixel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The nonlinear activation function $a(\\cdot)$ ensures, among other things, that the output of the network stays above 0. In fitting neuronal responses, we tend to use $a(x) = ELU(x) + 1$ where ELU (Exponential Linear Unit) is defined as follows:\n",
    "\n",
    "$$\n",
    "    ELU(x) = \n",
    "\\begin{cases}\n",
    "    e^x - 1, & x \\lt 0 \\\\\n",
    "    x,   & x \\ge 0\n",
    "\\end{cases}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting ELU function\n",
    "x = np.linspace(-2, 2)\n",
    "plt.plot(x, F.elu(torch.Tensor(x)))\n",
    "plt.axhline(0, c='r', ls='--')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We shift it by 1 to ensure it will always remain positive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting ELU+1 function\n",
    "x = np.linspace(-2, 2)\n",
    "plt.plot(x, F.elu(torch.Tensor(x))+1)\n",
    "plt.axhline(0, c='r', ls='--')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall, it can be seen that a linear-nonlinear is nothing more than a single linear layer on flattened image, followed by a nonlinear activation. Now let's go ahead and implment our LN model in PyTorch!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We therefore go ahead and implement a simple network consisting of a linear layer followed by ELU + 1 activation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_height,\n",
    "        input_width,\n",
    "        n_neurons,\n",
    "        momentum=0.1,\n",
    "        init_std=1e-3,\n",
    "        gamma=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(1, momentum=momentum, affine=False)\n",
    "        self.linear = nn.Linear(input_height * input_width, n_neurons)\n",
    "        self.gamma = gamma\n",
    "        self.init_std = init_std\n",
    "        self.initialize()\n",
    "        \n",
    "\n",
    "    def initialize(self, std=None):\n",
    "        if std is None:\n",
    "            std = self.init_std\n",
    "        nn.init.normal_(self.linear.weight.data, std=std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.linear(x.flatten(1))\n",
    "        return nn.functional.elu(x) + 1\n",
    "\n",
    "    def regularizer(self):\n",
    "        return self.gamma * self.linear.weight.abs().sum()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And that's it! We have now designed our first network model of the neuron's responses!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**BONUS**: notice that we used batch normalization (BN) layer right before the linear layer? This empirically helps to stabilize the training, allowing us to be not too sensitive to the weight and bias initialization. You could totally implement and train a LN network without such BN layer and you are more than welcome to try! However if you do, be very aware of the network weight initializations and the chocie of learning rate during the training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's instantiate the model before we move onto the next step of training the model!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ln_model = Linear(input_height=64, input_width=36, n_neurons=5335, gamma=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have a candidate model designed, it's time to train it. While we could use standard set of optimizers as provided by PyTorch to implement our training routine, here we are provided with a convenience function `train_model` that would handle a lot of the training boiler plate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from lviv.trainers import train_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Critically, `train_model` sets up training based on **Poisson loss** and also perform early stopping based on **correlation** of the predicted neuronal responses with the actual neuronal responses on the **validation set**. Let's now talk briefly about our objective (loss) function of choice in training neuron response models - the Poisson loss."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mathematical aside: Poisson Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### How we are **actually** modeling the noisy neuronal responses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The use of **Poisson loss** follows from the assumption that, *conditioned on the stimulus*, the neurons' responses follow an **independent Poisson** distribution. That is, given an input image $x$, the population response $\\mathbf{r}$ is distributed as:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{r} | x) = \\prod_i^N \\text{Poiss}(r_i; \\lambda_i(x))\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "where $r_i$ is the $i^\\text{th}$ neuron in the population $\\mathbf{r}$. The $\\lambda_i$ is the parameter for Poisson distribution that controls its **average value**. Here we express $\\lambda_i(x)$ to indicate the fact that the average response for each neuron is expected to vary *as a function of the input image*. We can express this average matching as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[r_i|x] = \\lambda_i(x)\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In fact, it is precise this function $\\lambda_i(x)$ that we are modeling using LN models and, in the next step, more complex neural networks. In otherwords, we are learning $\\lambda_i(x) = f_i(x, \\theta)$, where $\\theta$ is the trainable parameters of the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Putting all together, this means that, our model $f(x, \\theta)$ is really modeling the average activity of the neurons,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\mathbf{r}|x] = \\mathbf{f}(x, \\theta)\n",
    "$$\n",
    "\n",
    "while we are assuming that the neurons are distribution according to **independent Poisson** distribution around the average responses by our model $\\mathbf{f}(x, \\theta)$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Deriving the objective function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Poisson distribution is defined as follows:\n",
    "\n",
    "$$\n",
    "p(r) = \\text{Poiss}(r; \\lambda) = \\frac{e^{-\\lambda}\\lambda^{r}}{r!}\n",
    "$$\n",
    "\n",
    "During the training, we would want to adjust the model parameter $\\theta$ to maximize the chance of observing the response $\\mathbf{r}$ to a known image $x$. This is achieved by **maximizing** the log-likelihood function $\\log p(\\mathbf{r}|x, \\theta)$, or equivalently by **minimzing the negative log-likelihood function** as the objective function $L(x, \\mathbf{r}, \\theta)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(x, \\mathbf{r}, \\theta) &= -\\log p(\\mathbf{r}|x, \\theta) \\\\\n",
    "&= -\\log \\prod_i \\text{Poiss}(r_i; f_i(x, \\theta)) \\\\\n",
    "&= -\\sum_i \\log \\frac{e^{-f_i(x, \\theta)}f_i(x, \\theta)^{r_i}}{r_i!} \\\\\n",
    "&= \\sum_i \\left(f_i(x, \\theta) - r_i \\log f_i(x, \\theta) + \\log r_i! \\right)\n",
    "\\end{align}\n",
    "$$\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "During the optimization, we seek for $\\theta$ that would minimize the loss $L$. Note that since the term $log r_i!$ does not depend on $\\theta$, it can be safely dropped from Poisson loss. Hence you would commonly see the following expression as the definition of the **Poisson loss**\n",
    "\n",
    "$$\n",
    "L_\\text{Poiss}(x, \\mathbf{r}, \\theta) = \\sum_i \\left(f_i(x, \\theta) - r_i \\log f_i(x, \\theta)\\right)\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performing the training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the theoretical foundation for the training and the choice of the objective function under our belt, let's go ahead and train the network. Because the function `train_model` handles a lot underneath the hood, training a model is just as easy as invoking the function by passing it the model to be trained and the dataloaders!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from lviv.trainers import train_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "score, output, model_state = train_model(model=ln_model, dataloader=dataloaders)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================\n",
      "correlation -0.0019075753\n",
      "poisson_loss 9395851.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1: 100%|██████████| 150/150 [00:03<00:00, 44.69it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[001|00/05] ---> 0.05955984443426132\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================\n",
      "correlation 0.059559844\n",
      "poisson_loss 3384139.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2: 100%|██████████| 150/150 [00:00<00:00, 176.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[002|00/05] ---> 0.06592471897602081\n",
      "=======================================\n",
      "correlation 0.06592472\n",
      "poisson_loss 3274338.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3: 100%|██████████| 150/150 [00:00<00:00, 177.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[003|01/05] -/-> 0.06381010264158249\n",
      "=======================================\n",
      "correlation 0.0638101\n",
      "poisson_loss 3274534.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4: 100%|██████████| 150/150 [00:00<00:00, 174.58it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[004|01/05] ---> 0.07152469456195831\n",
      "=======================================\n",
      "correlation 0.071524695\n",
      "poisson_loss 3243809.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5: 100%|██████████| 150/150 [00:00<00:00, 175.18it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[005|00/05] ---> 0.07718321681022644\n",
      "=======================================\n",
      "correlation 0.07718322\n",
      "poisson_loss 3174631.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6: 100%|██████████| 150/150 [00:00<00:00, 176.82it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[006|00/05] ---> 0.07769027352333069\n",
      "=======================================\n",
      "correlation 0.07769027\n",
      "poisson_loss 3153348.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7: 100%|██████████| 150/150 [00:00<00:00, 176.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[007|01/05] -/-> 0.07006139308214188\n",
      "=======================================\n",
      "correlation 0.07006139\n",
      "poisson_loss 3368900.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8: 100%|██████████| 150/150 [00:00<00:00, 176.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[008|02/05] -/-> 0.06875057518482208\n",
      "=======================================\n",
      "correlation 0.068750575\n",
      "poisson_loss 3328448.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9: 100%|██████████| 150/150 [00:00<00:00, 177.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[009|03/05] -/-> 0.06966907531023026\n",
      "=======================================\n",
      "correlation 0.069669075\n",
      "poisson_loss 3304112.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10: 100%|██████████| 150/150 [00:00<00:00, 176.75it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[010|04/05] -/-> 0.0717167928814888\n",
      "=======================================\n",
      "correlation 0.07171679\n",
      "poisson_loss 3497721.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11: 100%|██████████| 150/150 [00:00<00:00, 173.33it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[011|05/05] -/-> 0.07496411353349686\n",
      "Restoring best model after lr decay! 0.074964 ---> 0.077690\n",
      "=======================================\n",
      "correlation 0.07769027\n",
      "poisson_loss 3153348.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12: 100%|██████████| 150/150 [00:00<00:00, 173.67it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    12: reducing learning rate of group 0 to 1.5000e-03.\n",
      "[012|01/05] -/-> 0.07143863290548325\n",
      "=======================================\n",
      "correlation 0.07143863\n",
      "poisson_loss 3309589.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13: 100%|██████████| 150/150 [00:00<00:00, 174.99it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[013|01/05] ---> 0.10395169258117676\n",
      "=======================================\n",
      "correlation 0.10395169\n",
      "poisson_loss 2500118.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14: 100%|██████████| 150/150 [00:00<00:00, 175.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[014|01/05] -/-> 0.10067544877529144\n",
      "=======================================\n",
      "correlation 0.10067545\n",
      "poisson_loss 2479766.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15: 100%|██████████| 150/150 [00:00<00:00, 177.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[015|02/05] -/-> 0.10142096132040024\n",
      "=======================================\n",
      "correlation 0.10142096\n",
      "poisson_loss 2414144.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 16: 100%|██████████| 150/150 [00:00<00:00, 176.30it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[016|03/05] -/-> 0.10160883516073227\n",
      "=======================================\n",
      "correlation 0.101608835\n",
      "poisson_loss 2430222.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 17: 100%|██████████| 150/150 [00:00<00:00, 176.67it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[017|04/05] -/-> 0.09739978611469269\n",
      "=======================================\n",
      "correlation 0.097399786\n",
      "poisson_loss 2449914.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 18: 100%|██████████| 150/150 [00:00<00:00, 170.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[018|05/05] -/-> 0.09415452182292938\n",
      "Restoring best model after lr decay! 0.094155 ---> 0.103952\n",
      "=======================================\n",
      "correlation 0.10395169\n",
      "poisson_loss 2500118.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 19: 100%|██████████| 150/150 [00:00<00:00, 176.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    19: reducing learning rate of group 0 to 4.5000e-04.\n",
      "[019|01/05] -/-> 0.09806245565414429\n",
      "=======================================\n",
      "correlation 0.098062456\n",
      "poisson_loss 2533733.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 20: 100%|██████████| 150/150 [00:00<00:00, 174.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[020|01/05] ---> 0.11151435226202011\n",
      "=======================================\n",
      "correlation 0.11151435\n",
      "poisson_loss 2310042.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 21: 100%|██████████| 150/150 [00:00<00:00, 175.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[021|01/05] -/-> 0.10864903032779694\n",
      "=======================================\n",
      "correlation 0.10864903\n",
      "poisson_loss 2329606.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 22: 100%|██████████| 150/150 [00:00<00:00, 176.26it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[022|02/05] -/-> 0.10798943787813187\n",
      "=======================================\n",
      "correlation 0.10798944\n",
      "poisson_loss 2349926.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 23: 100%|██████████| 150/150 [00:00<00:00, 176.19it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[023|03/05] -/-> 0.10652267187833786\n",
      "=======================================\n",
      "correlation 0.10652267\n",
      "poisson_loss 2274603.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 24: 100%|██████████| 150/150 [00:00<00:00, 175.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[024|04/05] -/-> 0.10494276136159897\n",
      "=======================================\n",
      "correlation 0.10494276\n",
      "poisson_loss 2338915.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 25: 100%|██████████| 150/150 [00:00<00:00, 177.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[025|05/05] -/-> 0.1067856028676033\n",
      "Restoring best model after lr decay! 0.106786 ---> 0.111514\n",
      "Restoring best model! 0.111514 ---> 0.111514\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnIjtCeERCjk",
    "outputId": "569f4934-9cb5-4253-ae02-001b6a9d7828"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyzing the trained network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Woohoo! We have now successfully trained our very first LN model on real neuronal responses! But really, how good is the model?\n",
    "\n",
    "During the training, the `train_model` function iteratively reported two values: the loss function (Poisson loss) value and the average correlation. \n",
    "\n",
    "But what is this correlation? It's simply the correlation computed between our predicted neuronal responses $\\hat{r}_i$ and the actual neuronal responses $r_i$ across images in the validation set. We then take the average correlation value **across neurons** to get average correlation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Being a correlation, the highest possible value is of course 1.0, but practically this is never reached both due to 1) imperfection of our model but more fundamentally due to the noiseness of the neuron's responses. Because of the noise, even a perfect model would never reach a correlation of 1.0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='red'>\n",
    "    NOTE TO SELF: Add more here probably plotting some scatter plot for an example neuron, histogram of correlation scores both done on the testset.\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Going beyond Linear-Nonlinear model by using CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We saw that a simple LN model can be trained to achieve above chance performance in predicting the responses of mouse V1 neurons to natural images. But we certainly must be able to do better than that, right?\n",
    "\n",
    "In the past decase, what has really driven system identification in visual neurons has been the use of convolutional neural networks (CNN). Below, we will try out a very simple CNN to see if we can already reach better performance than LN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='green'>\n",
    "    NOTE to collaborators: \n",
    "    Please add a simpler implementation of CNN. Ideally it would train just as fast as the simple fully connected linear model given above. \n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from collections import OrderedDict\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_height,\n",
    "        input_width,\n",
    "        n_neurons,\n",
    "        momentum=0.1,\n",
    "        init_std=1e-3,\n",
    "        gamma=0.1,\n",
    "        hidden_channels=8,\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "        self.init_std = init_std\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # CNN core\n",
    "        self.cnn_core = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv1\", nn.Conv2d(1, hidden_channels, 15, padding=15 // 2, bias=False)),\n",
    "                    (\"bn1\", nn.BatchNorm2d(hidden_channels, momentum=momentum)),\n",
    "                    (\"elu1\", nn.ELU()),\n",
    "                    (\"conv2\", nn.Conv2d(hidden_channels, hidden_channels, 13, padding=13 // 2, bias=False)),\n",
    "                    (\"bn2\", nn.BatchNorm2d(hidden_channels, momentum=momentum)),\n",
    "                    (\"elu2\", nn.ELU()),\n",
    "                    (\"conv3\", nn.Conv2d(hidden_channels, hidden_channels, 13, padding=13 // 2, bias=False)),\n",
    "                    (\"bn3\", nn.BatchNorm2d(hidden_channels, momentum=momentum)),\n",
    "                    (\"elu3\", nn.ELU()),\n",
    "                    (\"conv4\", nn.Conv2d(hidden_channels, hidden_channels, 13, padding=13 // 2, bias=False)),\n",
    "                    (\"bn4\", nn.BatchNorm2d(hidden_channels, momentum=momentum)),\n",
    "                    (\"elu4\", nn.ELU()),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Fully connected readout\n",
    "        self.readout = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    ('fc_ro', nn.Linear(input_height * input_width * hidden_channels, n_neurons)),\n",
    "                    ('bn_ro', nn.BatchNorm1d(n_neurons, momentum=momentum)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    def initialize(self, std=None):\n",
    "        if std is None:\n",
    "            std = self.init_std\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data, std=std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_core(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.readout(x)\n",
    "        return nn.functional.elu(x) + 1\n",
    "    \n",
    "    def regularizer(self):\n",
    "        return self.readout[0].weight.abs().sum() * self.gamma\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "cnn_model = CNN(input_height=64, input_width=36, n_neurons=5335)\n",
    "score, output, model_state = train_model(model=cnn_model, dataloader=dataloaders)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================\n",
      "correlation -0.00026665637\n",
      "poisson_loss 3374573.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1: 100%|██████████| 75/75 [00:07<00:00,  9.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[001|00/05] ---> 0.021236207336187363\n",
      "=======================================\n",
      "correlation 0.021236207\n",
      "poisson_loss 2463599.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2: 100%|██████████| 75/75 [00:05<00:00, 14.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[002|00/05] ---> 0.07052340358495712\n",
      "=======================================\n",
      "correlation 0.0705234\n",
      "poisson_loss 2113180.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3: 100%|██████████| 75/75 [00:05<00:00, 14.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[003|00/05] ---> 0.12169219553470612\n",
      "=======================================\n",
      "correlation 0.121692196\n",
      "poisson_loss 1951988.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4: 100%|██████████| 75/75 [00:05<00:00, 14.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[004|00/05] ---> 0.14366552233695984\n",
      "=======================================\n",
      "correlation 0.14366552\n",
      "poisson_loss 1886504.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5: 100%|██████████| 75/75 [00:05<00:00, 14.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[005|00/05] ---> 0.1598166525363922\n",
      "=======================================\n",
      "correlation 0.15981665\n",
      "poisson_loss 1853729.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6: 100%|██████████| 75/75 [00:05<00:00, 14.48it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[006|00/05] ---> 0.17508751153945923\n",
      "=======================================\n",
      "correlation 0.17508751\n",
      "poisson_loss 1839959.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7: 100%|██████████| 75/75 [00:05<00:00, 14.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[007|00/05] ---> 0.19102248549461365\n",
      "=======================================\n",
      "correlation 0.19102249\n",
      "poisson_loss 1814787.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8: 100%|██████████| 75/75 [00:05<00:00, 14.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[008|01/05] -/-> 0.18706892430782318\n",
      "=======================================\n",
      "correlation 0.18706892\n",
      "poisson_loss 1824098.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9: 100%|██████████| 75/75 [00:05<00:00, 14.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[009|01/05] ---> 0.20585818588733673\n",
      "=======================================\n",
      "correlation 0.20585819\n",
      "poisson_loss 1804795.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10: 100%|██████████| 75/75 [00:05<00:00, 14.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[010|00/05] ---> 0.20773445069789886\n",
      "=======================================\n",
      "correlation 0.20773445\n",
      "poisson_loss 1802806.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11: 100%|██████████| 75/75 [00:05<00:00, 14.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[011|01/05] -/-> 0.2031957507133484\n",
      "=======================================\n",
      "correlation 0.20319575\n",
      "poisson_loss 1812389.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12: 100%|██████████| 75/75 [00:05<00:00, 14.46it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[012|02/05] -/-> 0.1954425573348999\n",
      "=======================================\n",
      "correlation 0.19544256\n",
      "poisson_loss 1843691.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13: 100%|██████████| 75/75 [00:05<00:00, 14.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[013|03/05] -/-> 0.195707768201828\n",
      "=======================================\n",
      "correlation 0.19570777\n",
      "poisson_loss 1873333.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14: 100%|██████████| 75/75 [00:05<00:00, 14.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[014|04/05] -/-> 0.18757301568984985\n",
      "=======================================\n",
      "correlation 0.18757302\n",
      "poisson_loss 1916169.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15: 100%|██████████| 75/75 [00:05<00:00, 14.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[015|05/05] -/-> 0.17145362496376038\n",
      "Restoring best model after lr decay! 0.171454 ---> 0.207734\n",
      "=======================================\n",
      "correlation 0.20773445\n",
      "poisson_loss 1802806.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 16: 100%|██████████| 75/75 [00:05<00:00, 14.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    16: reducing learning rate of group 0 to 1.5000e-03.\n",
      "[016|01/05] -/-> 0.20370830595493317\n",
      "=======================================\n",
      "correlation 0.2037083\n",
      "poisson_loss 1818983.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 17: 100%|██████████| 75/75 [00:05<00:00, 14.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[017|02/05] -/-> 0.1997910439968109\n",
      "=======================================\n",
      "correlation 0.19979104\n",
      "poisson_loss 1815871.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 18: 100%|██████████| 75/75 [00:05<00:00, 14.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[018|03/05] -/-> 0.19749383628368378\n",
      "=======================================\n",
      "correlation 0.19749384\n",
      "poisson_loss 1829960.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 19: 100%|██████████| 75/75 [00:05<00:00, 14.35it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[019|04/05] -/-> 0.19291333854198456\n",
      "=======================================\n",
      "correlation 0.19291334\n",
      "poisson_loss 1849161.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 20: 100%|██████████| 75/75 [00:05<00:00, 14.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[020|05/05] -/-> 0.18776088953018188\n",
      "Restoring best model after lr decay! 0.187761 ---> 0.207734\n",
      "=======================================\n",
      "correlation 0.20773445\n",
      "poisson_loss 1802806.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 21: 100%|██████████| 75/75 [00:05<00:00, 14.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[021|01/05] -/-> 0.20450641214847565\n",
      "=======================================\n",
      "correlation 0.20450641\n",
      "poisson_loss 1801188.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 22: 100%|██████████| 75/75 [00:05<00:00, 14.35it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    22: reducing learning rate of group 0 to 4.5000e-04.\n",
      "[022|02/05] -/-> 0.20180119574069977\n",
      "=======================================\n",
      "correlation 0.2018012\n",
      "poisson_loss 1814779.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 23: 100%|██████████| 75/75 [00:05<00:00, 14.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[023|03/05] -/-> 0.20084376633167267\n",
      "=======================================\n",
      "correlation 0.20084377\n",
      "poisson_loss 1816706.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 24: 100%|██████████| 75/75 [00:05<00:00, 14.37it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[024|04/05] -/-> 0.19823312759399414\n",
      "=======================================\n",
      "correlation 0.19823313\n",
      "poisson_loss 1823781.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 25: 100%|██████████| 75/75 [00:05<00:00, 14.35it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[025|05/05] -/-> 0.1976805031299591\n",
      "Restoring best model after lr decay! 0.197681 ---> 0.207734\n",
      "Restoring best model! 0.207734 ---> 0.207734\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trying out the State-of-the-Art (SOTA) model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we got some sense on how we could go about training linear and nonlinear network models to predict V1 neuron responses to natural images, and we just saw how the nonlinear network seems to bring significant improvement to the performance beyond the LN network.\n",
    "\n",
    "You might now be wondering, how good can we get? To get a sense of this, let's go ahead and train a state-of-the-art (SOTA) network model for mouse V1 responses to natual images as published in our recent work in [Lurz et al. ICLR 2021](https://github.com/sinzlab/Lurz_2020_code).\n",
    "\n",
    "To keep things simple, I have provided for the network implementation in the `lviv` package, so you can build the model just by invoking a function!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from lviv.models import build_lurz2020_model\n",
    "model_config = {'init_mu_range': 0.55,\n",
    "                'init_sigma': 0.4,\n",
    "                'input_kern': 15,\n",
    "                'hidden_kern': 13,\n",
    "                'gamma_input': 1.0,\n",
    "                'grid_mean_predictor': {'type': 'cortex',\n",
    "                                        'input_dimensions': 2,\n",
    "                                        'hidden_layers': 0,\n",
    "                                        'hidden_features': 0,\n",
    "                                        'final_tanh': False},\n",
    "                'gamma_readout': 2.439\n",
    "               }\n",
    "\n",
    "sota_model = build_lurz2020_model(**model_config, dataloaders=dataloaders, seed=1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "score, output, model_state = train_model(model=sota_model, dataloader=dataloaders)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================\n",
      "correlation 0.00034036028\n",
      "poisson_loss 3467926.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1: 100%|██████████| 75/75 [00:05<00:00, 13.81it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[001|00/05] ---> 0.06802412122488022\n",
      "=======================================\n",
      "correlation 0.06802412\n",
      "poisson_loss 1933875.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2: 100%|██████████| 75/75 [00:02<00:00, 25.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[002|00/05] ---> 0.0992986261844635\n",
      "=======================================\n",
      "correlation 0.099298626\n",
      "poisson_loss 1907451.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3: 100%|██████████| 75/75 [00:02<00:00, 25.06it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[003|00/05] ---> 0.1352093517780304\n",
      "=======================================\n",
      "correlation 0.13520935\n",
      "poisson_loss 1867082.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4: 100%|██████████| 75/75 [00:02<00:00, 25.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[004|00/05] ---> 0.15988028049468994\n",
      "=======================================\n",
      "correlation 0.15988028\n",
      "poisson_loss 1841954.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5: 100%|██████████| 75/75 [00:03<00:00, 24.92it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[005|00/05] ---> 0.18220213055610657\n",
      "=======================================\n",
      "correlation 0.18220213\n",
      "poisson_loss 1817112.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6: 100%|██████████| 75/75 [00:03<00:00, 24.98it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[006|00/05] ---> 0.20671896636486053\n",
      "=======================================\n",
      "correlation 0.20671897\n",
      "poisson_loss 1790257.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7: 100%|██████████| 75/75 [00:02<00:00, 25.03it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[007|00/05] ---> 0.2238064408302307\n",
      "=======================================\n",
      "correlation 0.22380644\n",
      "poisson_loss 1772522.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8: 100%|██████████| 75/75 [00:03<00:00, 24.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[008|00/05] ---> 0.23007357120513916\n",
      "=======================================\n",
      "correlation 0.23007357\n",
      "poisson_loss 1773582.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9: 100%|██████████| 75/75 [00:02<00:00, 25.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[009|00/05] ---> 0.2451137751340866\n",
      "=======================================\n",
      "correlation 0.24511378\n",
      "poisson_loss 1747738.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10: 100%|██████████| 75/75 [00:02<00:00, 25.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[010|00/05] ---> 0.2503341734409332\n",
      "=======================================\n",
      "correlation 0.25033417\n",
      "poisson_loss 1738236.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11: 100%|██████████| 75/75 [00:03<00:00, 24.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[011|00/05] ---> 0.2632496654987335\n",
      "=======================================\n",
      "correlation 0.26324967\n",
      "poisson_loss 1725767.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12: 100%|██████████| 75/75 [00:03<00:00, 24.81it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[012|01/05] -/-> 0.2630777955055237\n",
      "=======================================\n",
      "correlation 0.2630778\n",
      "poisson_loss 1730036.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13: 100%|██████████| 75/75 [00:03<00:00, 24.98it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[013|01/05] ---> 0.2683514654636383\n",
      "=======================================\n",
      "correlation 0.26835147\n",
      "poisson_loss 1716713.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14: 100%|██████████| 75/75 [00:03<00:00, 24.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[014|00/05] ---> 0.2714916169643402\n",
      "=======================================\n",
      "correlation 0.27149162\n",
      "poisson_loss 1719224.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15: 100%|██████████| 75/75 [00:03<00:00, 24.79it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[015|00/05] ---> 0.27534162998199463\n",
      "=======================================\n",
      "correlation 0.27534163\n",
      "poisson_loss 1707011.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 16: 100%|██████████| 75/75 [00:03<00:00, 24.76it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[016|00/05] ---> 0.2800500690937042\n",
      "=======================================\n",
      "correlation 0.28005007\n",
      "poisson_loss 1706100.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 17: 100%|██████████| 75/75 [00:03<00:00, 24.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[017|01/05] -/-> 0.27785417437553406\n",
      "=======================================\n",
      "correlation 0.27785417\n",
      "poisson_loss 1704381.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 18: 100%|██████████| 75/75 [00:03<00:00, 24.81it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[018|01/05] ---> 0.28175079822540283\n",
      "=======================================\n",
      "correlation 0.2817508\n",
      "poisson_loss 1699185.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 19: 100%|██████████| 75/75 [00:03<00:00, 24.85it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[019|00/05] ---> 0.2833324372768402\n",
      "=======================================\n",
      "correlation 0.28333244\n",
      "poisson_loss 1700154.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 20: 100%|██████████| 75/75 [00:03<00:00, 24.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[020|01/05] -/-> 0.28235411643981934\n",
      "=======================================\n",
      "correlation 0.28235412\n",
      "poisson_loss 1703445.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 21: 100%|██████████| 75/75 [00:03<00:00, 24.79it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[021|01/05] ---> 0.28642159700393677\n",
      "=======================================\n",
      "correlation 0.2864216\n",
      "poisson_loss 1695235.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 22: 100%|██████████| 75/75 [00:03<00:00, 24.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[022|01/05] -/-> 0.2859250009059906\n",
      "=======================================\n",
      "correlation 0.285925\n",
      "poisson_loss 1698523.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 23: 100%|██████████| 75/75 [00:03<00:00, 24.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[023|01/05] ---> 0.288645476102829\n",
      "=======================================\n",
      "correlation 0.28864548\n",
      "poisson_loss 1692468.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 24: 100%|██████████| 75/75 [00:03<00:00, 24.76it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[024|01/05] -/-> 0.2806972563266754\n",
      "=======================================\n",
      "correlation 0.28069726\n",
      "poisson_loss 1711807.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 25: 100%|██████████| 75/75 [00:03<00:00, 24.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[025|02/05] -/-> 0.2866860628128052\n",
      "=======================================\n",
      "correlation 0.28668606\n",
      "poisson_loss 1700504.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 26: 100%|██████████| 75/75 [00:03<00:00, 24.67it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[026|02/05] ---> 0.2889840304851532\n",
      "=======================================\n",
      "correlation 0.28898403\n",
      "poisson_loss 1693454.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 27: 100%|██████████| 75/75 [00:03<00:00, 24.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[027|01/05] -/-> 0.2859857380390167\n",
      "=======================================\n",
      "correlation 0.28598574\n",
      "poisson_loss 1698242.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 28: 100%|██████████| 75/75 [00:03<00:00, 24.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[028|01/05] ---> 0.28960171341896057\n",
      "=======================================\n",
      "correlation 0.2896017\n",
      "poisson_loss 1692582.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 29: 100%|██████████| 75/75 [00:03<00:00, 24.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[029|01/05] -/-> 0.28838810324668884\n",
      "=======================================\n",
      "correlation 0.2883881\n",
      "poisson_loss 1694804.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 30: 100%|██████████| 75/75 [00:03<00:00, 24.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[030|02/05] -/-> 0.2858908772468567\n",
      "=======================================\n",
      "correlation 0.28589088\n",
      "poisson_loss 1699080.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 31: 100%|██████████| 75/75 [00:03<00:00, 24.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[031|03/05] -/-> 0.2874508500099182\n",
      "=======================================\n",
      "correlation 0.28745085\n",
      "poisson_loss 1699732.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 32: 100%|██████████| 75/75 [00:03<00:00, 24.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[032|03/05] ---> 0.2918298840522766\n",
      "=======================================\n",
      "correlation 0.29182988\n",
      "poisson_loss 1687696.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 33: 100%|██████████| 75/75 [00:03<00:00, 24.61it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[033|01/05] -/-> 0.28938397765159607\n",
      "=======================================\n",
      "correlation 0.28938398\n",
      "poisson_loss 1691673.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 34: 100%|██████████| 75/75 [00:03<00:00, 24.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[034|02/05] -/-> 0.287019819021225\n",
      "=======================================\n",
      "correlation 0.28701982\n",
      "poisson_loss 1693903.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 35: 100%|██████████| 75/75 [00:03<00:00, 24.58it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[035|03/05] -/-> 0.2877348065376282\n",
      "=======================================\n",
      "correlation 0.2877348\n",
      "poisson_loss 1697201.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 36: 100%|██████████| 75/75 [00:03<00:00, 24.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[036|04/05] -/-> 0.29016605019569397\n",
      "=======================================\n",
      "correlation 0.29016605\n",
      "poisson_loss 1694408.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 37: 100%|██████████| 75/75 [00:03<00:00, 24.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[037|05/05] -/-> 0.2860223948955536\n",
      "Restoring best model after lr decay! 0.286022 ---> 0.291830\n",
      "=======================================\n",
      "correlation 0.29182988\n",
      "poisson_loss 1687696.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 38: 100%|██████████| 75/75 [00:03<00:00, 24.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    38: reducing learning rate of group 0 to 1.5000e-03.\n",
      "[038|01/05] -/-> 0.28637316823005676\n",
      "=======================================\n",
      "correlation 0.28637317\n",
      "poisson_loss 1699175.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 39: 100%|██████████| 75/75 [00:03<00:00, 24.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[039|01/05] ---> 0.2965845465660095\n",
      "=======================================\n",
      "correlation 0.29658455\n",
      "poisson_loss 1678006.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 40: 100%|██████████| 75/75 [00:03<00:00, 24.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[040|01/05] -/-> 0.29545190930366516\n",
      "=======================================\n",
      "correlation 0.2954519\n",
      "poisson_loss 1679989.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 41: 100%|██████████| 75/75 [00:03<00:00, 24.48it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[041|02/05] -/-> 0.2956872284412384\n",
      "=======================================\n",
      "correlation 0.29568723\n",
      "poisson_loss 1680854.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 42: 100%|██████████| 75/75 [00:03<00:00, 24.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[042|03/05] -/-> 0.2916922867298126\n",
      "=======================================\n",
      "correlation 0.2916923\n",
      "poisson_loss 1694395.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 43: 100%|██████████| 75/75 [00:03<00:00, 24.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[043|04/05] -/-> 0.2909548878669739\n",
      "=======================================\n",
      "correlation 0.2909549\n",
      "poisson_loss 1692598.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 44: 100%|██████████| 75/75 [00:03<00:00, 24.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[044|05/05] -/-> 0.291450172662735\n",
      "Restoring best model after lr decay! 0.291450 ---> 0.296585\n",
      "=======================================\n",
      "correlation 0.29658455\n",
      "poisson_loss 1678006.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 45: 100%|██████████| 75/75 [00:03<00:00, 24.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    45: reducing learning rate of group 0 to 4.5000e-04.\n",
      "[045|01/05] -/-> 0.2958856225013733\n",
      "=======================================\n",
      "correlation 0.29588562\n",
      "poisson_loss 1680282.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 46: 100%|██████████| 75/75 [00:03<00:00, 24.46it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[046|01/05] ---> 0.2967185080051422\n",
      "=======================================\n",
      "correlation 0.2967185\n",
      "poisson_loss 1680080.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 47: 100%|██████████| 75/75 [00:03<00:00, 24.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[047|01/05] -/-> 0.2959626317024231\n",
      "=======================================\n",
      "correlation 0.29596263\n",
      "poisson_loss 1683020.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 48: 100%|██████████| 75/75 [00:03<00:00, 24.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[048|02/05] -/-> 0.2933180630207062\n",
      "=======================================\n",
      "correlation 0.29331806\n",
      "poisson_loss 1690638.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 49: 100%|██████████| 75/75 [00:03<00:00, 24.52it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[049|03/05] -/-> 0.2953323423862457\n",
      "=======================================\n",
      "correlation 0.29533234\n",
      "poisson_loss 1680719.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 50: 100%|██████████| 75/75 [00:03<00:00, 24.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[050|04/05] -/-> 0.2930465042591095\n",
      "=======================================\n",
      "correlation 0.2930465\n",
      "poisson_loss 1687981.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 51: 100%|██████████| 75/75 [00:03<00:00, 24.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[051|05/05] -/-> 0.29381123185157776\n",
      "Restoring best model after lr decay! 0.293811 ---> 0.296719\n",
      "Restoring best model! 0.296719 ---> 0.296719\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It turns out that we can have *linearized* version of the SOTA model. This effectively removes all nonlinear operations within the network except for the very last nonlinear activation, rendering the network into a **LN model** but with more complex architecture."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "linear_model_config = dict(model_config) # copy the config\n",
    "linear_model_config['linear'] = True # set linear to True to make it a LN model!\n",
    "\n",
    "sota_ln_model = build_lurz2020_model(**linear_model_config, dataloaders=dataloaders, seed=1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "score, output, model_state = train_model(model=sota_ln_model, dataloader=dataloaders)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================\n",
      "correlation 0.0003725943\n",
      "poisson_loss 3467901.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1: 100%|██████████| 75/75 [00:02<00:00, 25.07it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[001|00/05] ---> 0.03989261016249657\n",
      "=======================================\n",
      "correlation 0.03989261\n",
      "poisson_loss 1942624.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2: 100%|██████████| 75/75 [00:02<00:00, 25.37it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[002|00/05] ---> 0.0640023946762085\n",
      "=======================================\n",
      "correlation 0.064002395\n",
      "poisson_loss 1934634.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3: 100%|██████████| 75/75 [00:02<00:00, 25.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[003|00/05] ---> 0.08654235303401947\n",
      "=======================================\n",
      "correlation 0.08654235\n",
      "poisson_loss 1908961.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4: 100%|██████████| 75/75 [00:02<00:00, 25.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[004|00/05] ---> 0.10899844765663147\n",
      "=======================================\n",
      "correlation 0.10899845\n",
      "poisson_loss 1886000.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5: 100%|██████████| 75/75 [00:02<00:00, 25.37it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[005|00/05] ---> 0.11803299933671951\n",
      "=======================================\n",
      "correlation 0.118033\n",
      "poisson_loss 1880483.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6: 100%|██████████| 75/75 [00:02<00:00, 25.27it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[006|00/05] ---> 0.15008071064949036\n",
      "=======================================\n",
      "correlation 0.15008071\n",
      "poisson_loss 1849467.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7: 100%|██████████| 75/75 [00:02<00:00, 25.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[007|00/05] ---> 0.16414907574653625\n",
      "=======================================\n",
      "correlation 0.16414908\n",
      "poisson_loss 1836058.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8: 100%|██████████| 75/75 [00:02<00:00, 25.26it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[008|00/05] ---> 0.16947029531002045\n",
      "=======================================\n",
      "correlation 0.1694703\n",
      "poisson_loss 1828626.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9: 100%|██████████| 75/75 [00:02<00:00, 25.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[009|00/05] ---> 0.18100665509700775\n",
      "=======================================\n",
      "correlation 0.18100666\n",
      "poisson_loss 1820322.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10: 100%|██████████| 75/75 [00:02<00:00, 25.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[010|01/05] -/-> 0.1782236248254776\n",
      "=======================================\n",
      "correlation 0.17822362\n",
      "poisson_loss 1824116.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11: 100%|██████████| 75/75 [00:02<00:00, 25.21it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[011|01/05] ---> 0.19184549152851105\n",
      "=======================================\n",
      "correlation 0.19184549\n",
      "poisson_loss 1811927.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12: 100%|██████████| 75/75 [00:02<00:00, 25.17it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[012|01/05] -/-> 0.19147375226020813\n",
      "=======================================\n",
      "correlation 0.19147375\n",
      "poisson_loss 1815019.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13: 100%|██████████| 75/75 [00:02<00:00, 25.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[013|01/05] ---> 0.1979072391986847\n",
      "=======================================\n",
      "correlation 0.19790724\n",
      "poisson_loss 1804319.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14: 100%|██████████| 75/75 [00:02<00:00, 25.17it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[014|00/05] ---> 0.19898007810115814\n",
      "=======================================\n",
      "correlation 0.19898008\n",
      "poisson_loss 1807797.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15: 100%|██████████| 75/75 [00:02<00:00, 25.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[015|00/05] ---> 0.2010117471218109\n",
      "=======================================\n",
      "correlation 0.20101175\n",
      "poisson_loss 1807848.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 16: 100%|██████████| 75/75 [00:02<00:00, 25.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[016|00/05] ---> 0.20320378243923187\n",
      "=======================================\n",
      "correlation 0.20320378\n",
      "poisson_loss 1801370.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 17: 100%|██████████| 75/75 [00:02<00:00, 25.16it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[017|01/05] -/-> 0.1993752121925354\n",
      "=======================================\n",
      "correlation 0.19937521\n",
      "poisson_loss 1808326.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 18: 100%|██████████| 75/75 [00:02<00:00, 25.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[018|01/05] ---> 0.205960214138031\n",
      "=======================================\n",
      "correlation 0.20596021\n",
      "poisson_loss 1801451.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 19: 100%|██████████| 75/75 [00:02<00:00, 25.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[019|01/05] -/-> 0.20402778685092926\n",
      "=======================================\n",
      "correlation 0.20402779\n",
      "poisson_loss 1798513.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 20: 100%|██████████| 75/75 [00:02<00:00, 25.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[020|02/05] -/-> 0.20467354357242584\n",
      "=======================================\n",
      "correlation 0.20467354\n",
      "poisson_loss 1799656.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 21: 100%|██████████| 75/75 [00:02<00:00, 25.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[021|02/05] ---> 0.20845040678977966\n",
      "=======================================\n",
      "correlation 0.2084504\n",
      "poisson_loss 1800113.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 22: 100%|██████████| 75/75 [00:02<00:00, 25.10it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[022|01/05] -/-> 0.2050434798002243\n",
      "=======================================\n",
      "correlation 0.20504348\n",
      "poisson_loss 1798006.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 23: 100%|██████████| 75/75 [00:02<00:00, 25.03it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[023|01/05] ---> 0.20936203002929688\n",
      "=======================================\n",
      "correlation 0.20936203\n",
      "poisson_loss 1795215.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 24: 100%|██████████| 75/75 [00:03<00:00, 25.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[024|01/05] -/-> 0.20781029760837555\n",
      "=======================================\n",
      "correlation 0.2078103\n",
      "poisson_loss 1796684.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 25: 100%|██████████| 75/75 [00:02<00:00, 25.08it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[025|02/05] -/-> 0.20645810663700104\n",
      "=======================================\n",
      "correlation 0.2064581\n",
      "poisson_loss 1795902.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 26: 100%|██████████| 75/75 [00:03<00:00, 24.94it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[026|02/05] ---> 0.2096509486436844\n",
      "=======================================\n",
      "correlation 0.20965095\n",
      "poisson_loss 1791693.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 27: 100%|██████████| 75/75 [00:03<00:00, 24.82it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[027|00/05] ---> 0.2099665403366089\n",
      "=======================================\n",
      "correlation 0.20996654\n",
      "poisson_loss 1798599.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 28: 100%|██████████| 75/75 [00:03<00:00, 24.99it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[028|00/05] ---> 0.21039018034934998\n",
      "=======================================\n",
      "correlation 0.21039018\n",
      "poisson_loss 1793896.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 29: 100%|██████████| 75/75 [00:03<00:00, 24.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[029|01/05] -/-> 0.21003438532352448\n",
      "=======================================\n",
      "correlation 0.21003439\n",
      "poisson_loss 1792499.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 30: 100%|██████████| 75/75 [00:03<00:00, 24.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[030|02/05] -/-> 0.20726752281188965\n",
      "=======================================\n",
      "correlation 0.20726752\n",
      "poisson_loss 1793317.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 31: 100%|██████████| 75/75 [00:03<00:00, 24.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[031|03/05] -/-> 0.20869460701942444\n",
      "=======================================\n",
      "correlation 0.2086946\n",
      "poisson_loss 1794817.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 32: 100%|██████████| 75/75 [00:02<00:00, 25.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[032|03/05] ---> 0.21043340861797333\n",
      "=======================================\n",
      "correlation 0.21043341\n",
      "poisson_loss 1791597.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 33: 100%|██████████| 75/75 [00:03<00:00, 24.85it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[033|01/05] -/-> 0.20852626860141754\n",
      "=======================================\n",
      "correlation 0.20852627\n",
      "poisson_loss 1795419.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 34: 100%|██████████| 75/75 [00:02<00:00, 25.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[034|02/05] -/-> 0.2086144983768463\n",
      "=======================================\n",
      "correlation 0.2086145\n",
      "poisson_loss 1791747.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 35: 100%|██████████| 75/75 [00:02<00:00, 25.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[035|03/05] -/-> 0.20981113612651825\n",
      "=======================================\n",
      "correlation 0.20981114\n",
      "poisson_loss 1790924.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 36: 100%|██████████| 75/75 [00:02<00:00, 25.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[036|03/05] ---> 0.21132226288318634\n",
      "=======================================\n",
      "correlation 0.21132226\n",
      "poisson_loss 1791852.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 37: 100%|██████████| 75/75 [00:03<00:00, 24.95it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[037|01/05] -/-> 0.2088499665260315\n",
      "=======================================\n",
      "correlation 0.20884997\n",
      "poisson_loss 1792172.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 38: 100%|██████████| 75/75 [00:03<00:00, 24.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[038|02/05] -/-> 0.21113260090351105\n",
      "=======================================\n",
      "correlation 0.2111326\n",
      "poisson_loss 1790932.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 39: 100%|██████████| 75/75 [00:03<00:00, 24.95it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[039|03/05] -/-> 0.20908276736736298\n",
      "=======================================\n",
      "correlation 0.20908277\n",
      "poisson_loss 1793538.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 40: 100%|██████████| 75/75 [00:03<00:00, 24.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[040|04/05] -/-> 0.20785950124263763\n",
      "=======================================\n",
      "correlation 0.2078595\n",
      "poisson_loss 1790864.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 41: 100%|██████████| 75/75 [00:03<00:00, 24.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[041|04/05] ---> 0.21220038831233978\n",
      "=======================================\n",
      "correlation 0.21220039\n",
      "poisson_loss 1791502.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 42: 100%|██████████| 75/75 [00:02<00:00, 25.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[042|01/05] -/-> 0.21125632524490356\n",
      "=======================================\n",
      "correlation 0.21125633\n",
      "poisson_loss 1789609.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 43: 100%|██████████| 75/75 [00:03<00:00, 24.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[043|02/05] -/-> 0.2091347724199295\n",
      "=======================================\n",
      "correlation 0.20913477\n",
      "poisson_loss 1793667.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 44: 100%|██████████| 75/75 [00:03<00:00, 24.81it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[044|02/05] ---> 0.21301040053367615\n",
      "=======================================\n",
      "correlation 0.2130104\n",
      "poisson_loss 1787558.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 45: 100%|██████████| 75/75 [00:03<00:00, 24.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[045|01/05] -/-> 0.20996084809303284\n",
      "=======================================\n",
      "correlation 0.20996085\n",
      "poisson_loss 1792363.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 46: 100%|██████████| 75/75 [00:03<00:00, 24.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[046|02/05] -/-> 0.2124241292476654\n",
      "=======================================\n",
      "correlation 0.21242413\n",
      "poisson_loss 1793335.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 47: 100%|██████████| 75/75 [00:03<00:00, 24.86it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[047|03/05] -/-> 0.21130309998989105\n",
      "=======================================\n",
      "correlation 0.2113031\n",
      "poisson_loss 1795883.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 48: 100%|██████████| 75/75 [00:03<00:00, 24.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[048|04/05] -/-> 0.21213102340698242\n",
      "=======================================\n",
      "correlation 0.21213102\n",
      "poisson_loss 1790908.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 49: 100%|██████████| 75/75 [00:03<00:00, 24.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[049|04/05] ---> 0.2131062150001526\n",
      "=======================================\n",
      "correlation 0.21310622\n",
      "poisson_loss 1789308.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 50: 100%|██████████| 75/75 [00:03<00:00, 24.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[050|00/05] ---> 0.2131325751543045\n",
      "=======================================\n",
      "correlation 0.21313258\n",
      "poisson_loss 1789284.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 51: 100%|██████████| 75/75 [00:03<00:00, 24.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[051|01/05] -/-> 0.21203437447547913\n",
      "=======================================\n",
      "correlation 0.21203437\n",
      "poisson_loss 1789427.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 52: 100%|██████████| 75/75 [00:03<00:00, 24.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[052|02/05] -/-> 0.21266917884349823\n",
      "=======================================\n",
      "correlation 0.21266918\n",
      "poisson_loss 1788396.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 53: 100%|██████████| 75/75 [00:03<00:00, 24.82it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[053|03/05] -/-> 0.21141599118709564\n",
      "=======================================\n",
      "correlation 0.21141599\n",
      "poisson_loss 1790947.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 54: 100%|██████████| 75/75 [00:03<00:00, 24.88it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[054|04/05] -/-> 0.21097949147224426\n",
      "=======================================\n",
      "correlation 0.21097949\n",
      "poisson_loss 1793532.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 55: 100%|██████████| 75/75 [00:03<00:00, 24.76it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[055|04/05] ---> 0.2139870822429657\n",
      "=======================================\n",
      "correlation 0.21398708\n",
      "poisson_loss 1786535.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 56: 100%|██████████| 75/75 [00:03<00:00, 24.75it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[056|01/05] -/-> 0.21326898038387299\n",
      "=======================================\n",
      "correlation 0.21326898\n",
      "poisson_loss 1789691.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 57: 100%|██████████| 75/75 [00:03<00:00, 24.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[057|02/05] -/-> 0.21298271417617798\n",
      "=======================================\n",
      "correlation 0.21298271\n",
      "poisson_loss 1787878.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 58: 100%|██████████| 75/75 [00:03<00:00, 24.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[058|02/05] ---> 0.21534930169582367\n",
      "=======================================\n",
      "correlation 0.2153493\n",
      "poisson_loss 1785949.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 59: 100%|██████████| 75/75 [00:03<00:00, 24.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[059|01/05] -/-> 0.21061821281909943\n",
      "=======================================\n",
      "correlation 0.21061821\n",
      "poisson_loss 1792914.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 60: 100%|██████████| 75/75 [00:03<00:00, 24.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[060|02/05] -/-> 0.2108164131641388\n",
      "=======================================\n",
      "correlation 0.21081641\n",
      "poisson_loss 1791379.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 61: 100%|██████████| 75/75 [00:03<00:00, 24.75it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[061|03/05] -/-> 0.21227073669433594\n",
      "=======================================\n",
      "correlation 0.21227074\n",
      "poisson_loss 1789170.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 62: 100%|██████████| 75/75 [00:03<00:00, 24.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[062|04/05] -/-> 0.21273402869701385\n",
      "=======================================\n",
      "correlation 0.21273403\n",
      "poisson_loss 1786976.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 63: 100%|██████████| 75/75 [00:03<00:00, 24.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[063|05/05] -/-> 0.213327556848526\n",
      "Restoring best model after lr decay! 0.213328 ---> 0.215349\n",
      "=======================================\n",
      "correlation 0.2153493\n",
      "poisson_loss 1785949.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 64: 100%|██████████| 75/75 [00:03<00:00, 24.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    64: reducing learning rate of group 0 to 1.5000e-03.\n",
      "[064|01/05] -/-> 0.21077997982501984\n",
      "=======================================\n",
      "correlation 0.21077998\n",
      "poisson_loss 1788606.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 65: 100%|██████████| 75/75 [00:03<00:00, 24.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[065|01/05] ---> 0.2161131054162979\n",
      "=======================================\n",
      "correlation 0.2161131\n",
      "poisson_loss 1784189.4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 66: 100%|██████████| 75/75 [00:03<00:00, 24.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[066|01/05] -/-> 0.21527814865112305\n",
      "=======================================\n",
      "correlation 0.21527815\n",
      "poisson_loss 1782393.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 67: 100%|██████████| 75/75 [00:03<00:00, 24.66it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[067|01/05] ---> 0.21654729545116425\n",
      "=======================================\n",
      "correlation 0.2165473\n",
      "poisson_loss 1786100.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 68: 100%|██████████| 75/75 [00:03<00:00, 24.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[068|00/05] ---> 0.21657902002334595\n",
      "=======================================\n",
      "correlation 0.21657902\n",
      "poisson_loss 1782611.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 69: 100%|██████████| 75/75 [00:03<00:00, 24.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[069|01/05] -/-> 0.2157956212759018\n",
      "=======================================\n",
      "correlation 0.21579562\n",
      "poisson_loss 1783768.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 70: 100%|██████████| 75/75 [00:03<00:00, 24.67it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[070|02/05] -/-> 0.21545611321926117\n",
      "=======================================\n",
      "correlation 0.21545611\n",
      "poisson_loss 1783396.9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 71: 100%|██████████| 75/75 [00:03<00:00, 24.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[071|03/05] -/-> 0.21577994525432587\n",
      "=======================================\n",
      "correlation 0.21577995\n",
      "poisson_loss 1783189.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 72: 100%|██████████| 75/75 [00:03<00:00, 24.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[072|04/05] -/-> 0.2163112908601761\n",
      "=======================================\n",
      "correlation 0.21631129\n",
      "poisson_loss 1783035.8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 73: 100%|██████████| 75/75 [00:03<00:00, 24.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[073|05/05] -/-> 0.21508441865444183\n",
      "Restoring best model after lr decay! 0.215084 ---> 0.216579\n",
      "=======================================\n",
      "correlation 0.21657902\n",
      "poisson_loss 1782611.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 74: 100%|██████████| 75/75 [00:03<00:00, 24.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    74: reducing learning rate of group 0 to 4.5000e-04.\n",
      "[074|01/05] -/-> 0.21494963765144348\n",
      "=======================================\n",
      "correlation 0.21494964\n",
      "poisson_loss 1783346.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 75: 100%|██████████| 75/75 [00:03<00:00, 24.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[075|02/05] -/-> 0.21574270725250244\n",
      "=======================================\n",
      "correlation 0.2157427\n",
      "poisson_loss 1783427.6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 76: 100%|██████████| 75/75 [00:03<00:00, 24.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[076|03/05] -/-> 0.21586337685585022\n",
      "=======================================\n",
      "correlation 0.21586338\n",
      "poisson_loss 1781771.1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 77: 100%|██████████| 75/75 [00:03<00:00, 24.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[077|04/05] -/-> 0.2163427770137787\n",
      "=======================================\n",
      "correlation 0.21634278\n",
      "poisson_loss 1783975.2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 78: 100%|██████████| 75/75 [00:03<00:00, 24.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[078|05/05] -/-> 0.21499189734458923\n",
      "Restoring best model after lr decay! 0.214992 ---> 0.216579\n",
      "Restoring best model! 0.216579 ---> 0.216579\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyzing the trained model to gain insights into the brain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='green'>\n",
    "    NOTE to collaborators: \n",
    "    Please provide code for generating gradient receptive field and MEI for the sota networks. By this point, they should have `sota_model` and `sota_ln_model` corresponding to the best nonlinear and linear model based on the model architecture as found in Lurz et al. 2021.\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "neuron_idx = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "def generate_grad_rf(model, starting_point, neuron_idx):\n",
    "    assert starting_point.ndim == 2\n",
    "    x = torch.tensor(starting_point.copy()[None, None, ...], dtype=torch.float, device='cuda', requires_grad=True)\n",
    "    model_activation = model(x)[:,neuron_idx]\n",
    "    model_activation.backward()\n",
    "    grad_rf = x.grad.data.cpu().numpy().squeeze()\n",
    "    return grad_rf\n",
    "\n",
    "\n",
    "# generate a gradient receptive field from the sota_model and the sota_ln_model\n",
    "grad_rf_sota = generate_grad_rf(sota_model, starting_point=np.zeros((36, 64)), neuron_idx=neuron_idx)\n",
    "grad_rf_sota_ln = generate_grad_rf(sota_ln_model, starting_point=np.zeros((36, 64)), neuron_idx=neuron_idx)\n",
    "\n",
    "# compare the two grad_rfs\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "axes[0].imshow(grad_rf_sota, cmap='gray')\n",
    "axes[0].set_title('SOTA')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(grad_rf_sota_ln, cmap='gray')\n",
    "axes[1].set_title('SOTA_ln')\n",
    "axes[1].axis('off')\n",
    "plt.suptitle('Gradient receptive fields', y=0.8)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0.8, 'Gradient receptive fields')"
      ]
     },
     "metadata": {},
     "execution_count": 103
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ],
      "image/png": "",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"192.835227pt\" version=\"1.1\" viewBox=\"0 0 572.4 192.835227\" width=\"572.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-07-26T08:36:45.594804</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 192.835227 \nL 572.4 192.835227 \nL 572.4 -0 \nL 0 -0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#pe354fee3c3)\">\n    <image height=\"143\" id=\"image8a59cf1ad7\" transform=\"scale(1 -1)translate(0 -143)\" width=\"254\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-42.635227\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- SOTA -->\n    <g transform=\"translate(118.181932 36.964773)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n      <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 19.140625 63.90625 8.859375 \nQ 54.734375 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.828125 \nQ 5.609375 19.09375 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nz\n\" id=\"DejaVuSans-79\"/>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-83\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-79\"/>\n     <use x=\"142.1875\" xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"195.521484\" xlink:href=\"#DejaVuSans-65\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g clip-path=\"url(#pb4cf503e1d)\">\n    <image height=\"143\" id=\"image925b87bf7f\" transform=\"scale(1 -1)translate(0 -143)\" width=\"254\" x=\"311.563636\" xlink:href=\"data:image/png;base64,\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\" y=\"-42.635227\"/>\n   </g>\n   <g id=\"text_2\">\n    <!-- SOTA_ln -->\n    <g transform=\"translate(414.076193 36.964773)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-83\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-79\"/>\n     <use x=\"142.1875\" xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"195.521484\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"263.929688\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"313.929688\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"341.712891\" xlink:href=\"#DejaVuSans-110\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"text_3\">\n   <!-- Gradient receptive fields -->\n   <g transform=\"translate(203.113125 16.318125)scale(0.12 -0.12)\">\n    <defs>\n     <path d=\"M 59.515625 10.40625 \nL 59.515625 29.984375 \nL 43.40625 29.984375 \nL 43.40625 38.09375 \nL 69.28125 38.09375 \nL 69.28125 6.78125 \nQ 63.578125 2.734375 56.6875 0.65625 \nQ 49.8125 -1.421875 42 -1.421875 \nQ 24.90625 -1.421875 15.25 8.5625 \nQ 5.609375 18.5625 5.609375 36.375 \nQ 5.609375 54.25 15.25 64.234375 \nQ 24.90625 74.21875 42 74.21875 \nQ 49.125 74.21875 55.546875 72.453125 \nQ 61.96875 70.703125 67.390625 67.28125 \nL 67.390625 56.78125 \nQ 61.921875 61.421875 55.765625 63.765625 \nQ 49.609375 66.109375 42.828125 66.109375 \nQ 29.4375 66.109375 22.71875 58.640625 \nQ 16.015625 51.171875 16.015625 36.375 \nQ 16.015625 21.625 22.71875 14.15625 \nQ 29.4375 6.6875 42.828125 6.6875 \nQ 48.046875 6.6875 52.140625 7.59375 \nQ 56.25 8.5 59.515625 10.40625 \nz\n\" id=\"DejaVuSans-71\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n     <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n     <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <use xlink:href=\"#DejaVuSans-71\"/>\n    <use x=\"77.490234\" xlink:href=\"#DejaVuSans-114\"/>\n    <use x=\"118.603516\" xlink:href=\"#DejaVuSans-97\"/>\n    <use x=\"179.882812\" xlink:href=\"#DejaVuSans-100\"/>\n    <use x=\"243.359375\" xlink:href=\"#DejaVuSans-105\"/>\n    <use x=\"271.142578\" xlink:href=\"#DejaVuSans-101\"/>\n    <use x=\"332.666016\" xlink:href=\"#DejaVuSans-110\"/>\n    <use x=\"396.044922\" xlink:href=\"#DejaVuSans-116\"/>\n    <use x=\"435.253906\" xlink:href=\"#DejaVuSans-32\"/>\n    <use x=\"467.041016\" xlink:href=\"#DejaVuSans-114\"/>\n    <use x=\"505.904297\" xlink:href=\"#DejaVuSans-101\"/>\n    <use x=\"567.427734\" xlink:href=\"#DejaVuSans-99\"/>\n    <use x=\"622.408203\" xlink:href=\"#DejaVuSans-101\"/>\n    <use x=\"683.931641\" xlink:href=\"#DejaVuSans-112\"/>\n    <use x=\"747.408203\" xlink:href=\"#DejaVuSans-116\"/>\n    <use x=\"786.617188\" xlink:href=\"#DejaVuSans-105\"/>\n    <use x=\"814.400391\" xlink:href=\"#DejaVuSans-118\"/>\n    <use x=\"873.580078\" xlink:href=\"#DejaVuSans-101\"/>\n    <use x=\"935.103516\" xlink:href=\"#DejaVuSans-32\"/>\n    <use x=\"966.890625\" xlink:href=\"#DejaVuSans-102\"/>\n    <use x=\"1002.095703\" xlink:href=\"#DejaVuSans-105\"/>\n    <use x=\"1029.878906\" xlink:href=\"#DejaVuSans-101\"/>\n    <use x=\"1091.402344\" xlink:href=\"#DejaVuSans-108\"/>\n    <use x=\"1119.185547\" xlink:href=\"#DejaVuSans-100\"/>\n    <use x=\"1182.662109\" xlink:href=\"#DejaVuSans-115\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe354fee3c3\">\n   <rect height=\"142.670455\" width=\"253.636364\" x=\"7.2\" y=\"42.964773\"/>\n  </clipPath>\n  <clipPath id=\"pb4cf503e1d\">\n   <rect height=\"142.670455\" width=\"253.636364\" x=\"311.563636\" y=\"42.964773\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "from tqdm import tqdm\n",
    "def generate_mei(model, starting_point, neuron_idx, iterations, std_constr=1):\n",
    "    assert starting_point.ndim == 2\n",
    "    x = torch.tensor(starting_point.copy()[None, None, ...], dtype=torch.float, device='cuda', requires_grad=True)\n",
    "    optimizer = torch.optim.SGD([x], lr=1, momentum=0.9)\n",
    "    model_activations = []\n",
    "    for i in tqdm(range(iterations)):\n",
    "        model_activation = model(x)[:,neuron_idx]\n",
    "        (-model_activation).backward()\n",
    "        model_activations.append(model_activation.detach().cpu().numpy())\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            x[:] = x / x.std() * std_constr\n",
    "    return np.array(model_activations), x.detach().cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "# generate a gradient receptive field from the sota_model and the sota_ln_model\n",
    "activation_sota, mei_sota = generate_mei(sota_model, starting_point=np.zeros((36, 64)), neuron_idx=neuron_idx, iterations=500)\n",
    "activation_sota_ln, mei_sota_ln = generate_mei(sota_ln_model, starting_point=np.zeros((36, 64)), neuron_idx=neuron_idx, iterations=500)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 149.61it/s]\n",
      "100%|██████████| 500/500 [00:03<00:00, 154.14it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "\n",
    "# compare the two grad_rfs\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "axes[0].imshow(mei_sota, cmap='gray')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('SOTA')\n",
    "axes[1].imshow(mei_sota_ln, cmap='gray')\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('SOTA_ln')\n",
    "plt.suptitle('MEIs', y=0.8)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0.8, 'MEIs')"
      ]
     },
     "metadata": {},
     "execution_count": 115
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ],
      "image/png": "",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"192.835227pt\" version=\"1.1\" viewBox=\"0 0 572.4 192.835227\" width=\"572.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-07-26T08:39:15.973678</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 192.835227 \nL 572.4 192.835227 \nL 572.4 -0 \nL 0 -0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g clip-path=\"url(#pb1a3ae6e3b)\">\n    <image height=\"143\" id=\"image59593abd8d\" transform=\"scale(1 -1)translate(0 -143)\" width=\"254\" x=\"7.2\" xlink:href=\"data:image/png;base64,\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\" y=\"-42.635227\"/>\n   </g>\n   <g id=\"text_1\">\n    <!-- SOTA -->\n    <g transform=\"translate(118.181932 36.964773)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n      <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 19.140625 63.90625 8.859375 \nQ 54.734375 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.828125 \nQ 5.609375 19.09375 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nz\n\" id=\"DejaVuSans-79\"/>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-83\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-79\"/>\n     <use x=\"142.1875\" xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"195.521484\" xlink:href=\"#DejaVuSans-65\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g clip-path=\"url(#pff7226e76e)\">\n    <image height=\"143\" id=\"image70fed2cacc\" transform=\"scale(1 -1)translate(0 -143)\" width=\"254\" x=\"311.563636\" xlink:href=\"data:image/png;base64,\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\" y=\"-42.635227\"/>\n   </g>\n   <g id=\"text_2\">\n    <!-- SOTA_ln -->\n    <g transform=\"translate(414.076193 36.964773)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-83\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-79\"/>\n     <use x=\"142.1875\" xlink:href=\"#DejaVuSans-84\"/>\n     <use x=\"195.521484\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"263.929688\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"313.929688\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"341.712891\" xlink:href=\"#DejaVuSans-110\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"text_3\">\n   <!-- MEIs -->\n   <g transform=\"translate(263.33625 16.318125)scale(0.12 -0.12)\">\n    <defs>\n     <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n     <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n     <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-73\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <use xlink:href=\"#DejaVuSans-77\"/>\n    <use x=\"86.279297\" xlink:href=\"#DejaVuSans-69\"/>\n    <use x=\"149.462891\" xlink:href=\"#DejaVuSans-73\"/>\n    <use x=\"178.955078\" xlink:href=\"#DejaVuSans-115\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb1a3ae6e3b\">\n   <rect height=\"142.670455\" width=\"253.636364\" x=\"7.2\" y=\"42.964773\"/>\n  </clipPath>\n  <clipPath id=\"pff7226e76e\">\n   <rect height=\"142.670455\" width=\"253.636364\" x=\"311.563636\" y=\"42.964773\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IVIV_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}